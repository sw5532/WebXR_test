<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Basic WebXR Depth Test</title>
    <style>
        body {
            margin: 0;
            font-family: sans-serif;
        }

        #ar-container {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        #glCanvas {
            width: 100%;
            height: 100%;
        }

        #overlay {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            justify-content: space-between;
            pointer-events: none;
            color: white;
            text-shadow: 1px 1px 2px black;
        }

        .info-box,
        #start-button {
            pointer-events: auto;
        }

        .info-box {
            margin: 1em;
            padding: 1em;
            background: rgba(0, 0, 0, 0.6);
            border-radius: 8px;
        }

        #start-button {
            margin: 1em auto;
            padding: 12px 24px;
            border: none;
            background-color: #007bff;
            color: white;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
        }
    </style>
</head>

<body>
    <div id="ar-container"><canvas id="glCanvas"></canvas></div>
    <div id="overlay">
        <div class="info-box">
            <div>Status: <span id="status">Ready</span></div>
            <div>Depth at Center: <span id="depth-display">N/A</span></div>
        </div>
        <button id="start-button">Start AR</button>
    </div>

    <script>
        const startButton = document.getElementById('start-button');
        const statusEl = document.getElementById('status');
        const depthEl = document.getElementById('depth-display');
        const overlayEl = document.getElementById('overlay');
        const glCanvas = document.getElementById('glCanvas');

        let xrSession = null;
        let gl = null;
        let xrReferenceSpace = null;
        let hasDepthFeature = false;

        document.addEventListener('DOMContentLoaded', () => {
            if (!navigator.xr) {
                statusEl.textContent = "WebXR not supported by this browser.";
                startButton.disabled = true;
                return;
            }
            startButton.addEventListener('click', onStartButtonClick);
        });

        function onStartButtonClick() {
            if (xrSession) {
                xrSession.end();
            } else {
                if (window.location.protocol !== 'https:') {
                    statusEl.textContent = "WebXR requires a secure context (HTTPS).";
                    return;
                }
                requestARSession();
            }
        }

        async function requestARSession() {
            statusEl.textContent = "Requesting AR session...";
            try {
                const session = await navigator.xr.requestSession("immersive-ar", {
                    requiredFeatures: ['local'],
                    optionalFeatures: ['dom-overlay', 'depth-sensing'],
                    domOverlay: { root: overlayEl },
                    depthSensing: {
                        usagePreference: ["cpu-optimized"],
                        dataFormatPreference: ["luminance-alpha"]
                    }
                });
                onSessionStarted(session);
            } catch (error) {
                console.error("WebXR session request failed:", error);
                statusEl.textContent = `Error: ${error.message}`;
            }
        }

        async function onSessionStarted(session) {
            xrSession = session;
            startButton.textContent = "Exit AR";
            session.addEventListener('end', onSessionEnded);

            // Check if the browser actually granted depth sensing
            if (session.depthUsage) {
                hasDepthFeature = true;
                statusEl.textContent = `AR Active | Depth format: ${session.depthDataFormat}`;
            } else {
                hasDepthFeature = false;
                statusEl.textContent = "AR Active (Depth Sensing NOT supported/granted)";
                depthEl.textContent = "Not supported by device or browser.";
            }

            // A WebGL layer is still required to show the camera feed
            try {
                gl = glCanvas.getContext('webgl', { xrCompatible: true });
                await gl.makeXRCompatible();
                const glLayer = new XRWebGLLayer(xrSession, gl);
                session.updateRenderState({ baseLayer: glLayer });
            } catch (e) {
                statusEl.textContent = `Error: Could not create WebGL layer. ${e.message}`;
                session.end();
                return;
            }

            xrReferenceSpace = await session.requestReferenceSpace('local');
            session.requestAnimationFrame(onXRFrame);
        }

        function onSessionEnded() {
            xrSession = null;
            gl = null;
            statusEl.textContent = "Ready";
            startButton.textContent = "Start AR";
            depthEl.textContent = "N/A";
            hasDepthFeature = false;
        }

        function onXRFrame(time, frame) {
            if (!xrSession) return;
            xrSession.requestAnimationFrame(onXRFrame);

            const pose = frame.getViewerPose(xrReferenceSpace);
            if (!pose) {
                depthEl.textContent = "Tracking lost. Move device.";
                return; // Can't do anything without a pose.
            }

            const glLayer = session.renderState.baseLayer;

            // This is the critical part that was missing.
            // We must bind the framebuffer and set the viewport for each frame.
            gl.bindFramebuffer(gl.FRAMEBUFFER, glLayer.framebuffer);

            // Also, clear the buffer to prevent artifacts from previous frames.
            // The clear color is transparent black (alpha = 0), so we see the camera behind it.
            gl.clearColor(0, 0, 0, 0);
            gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

            const view = pose.views[0];
            if (view) {
                // Get the viewport for this specific view and apply it.
                // This tells WebGL WHERE to draw on the framebuffer.
                const viewport = glLayer.getViewport(view);
                gl.viewport(viewport.x, viewport.y, viewport.width, viewport.height);

                // Now, we can proceed with trying to get depth information.
                if (hasDepthFeature) {
                    const depthInfo = frame.getDepthInformation(view);
                    if (depthInfo) {
                        // SUCCESS! We have depth data.
                        const centerX = Math.floor(depthInfo.width / 2);
                        const centerY = Math.floor(depthInfo.height / 2);
                        const depthInMeters = depthInfo.getDepthInMeters(centerX, centerY);

                        if (depthInMeters) {
                            depthEl.textContent = `${depthInMeters.toFixed(2)}m`;
                        } else {
                            depthEl.textContent = "Depth unknown at center";
                        }
                    } else {
                        // This is the state where the system is working but needs more data.
                        depthEl.textContent = "Initializing... Move device slowly to scan.";
                    }
                }
            }
        }
    </script>
</body>

</html>