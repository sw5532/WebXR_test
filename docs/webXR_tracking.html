<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Robust WebXR Image Tracking</title>
  <script src="https://unpkg.com/three@0.126.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.126.0/examples/js/loaders/GLTFLoader.js"></script>
  <style>
    body { margin: 0; overflow: hidden; font-family: sans-serif; }
    canvas { display: block; }
    #info { position: absolute; top: 10px; width: 100%; text-align: center; z-index: 100; color: white; font-size: 16px; background-color: rgba(0,0,0,0.7); padding: 10px; box-sizing: border-box;}
    button { font-size: 18px; padding: 12px 20px; position:absolute; bottom: 20px; left: 50%; transform: translateX(-50%); z-index: 100; border-radius: 8px; border: none; background-color: #007aff; color: white; }
    button:disabled { background-color: #555; }
  </style>
</head>
<body>
  <div id="info">Checking for WebXR support...</div>
  <button id="start-button" disabled>Start AR</button>

  <script>
    const startButton = document.getElementById('start-button');
    const infoElement = document.getElementById('info');

    // --- Best Practice: Check for support first ---
    document.addEventListener('DOMContentLoaded', async () => {
      if (navigator.xr) {
        // isSessionSupported is the first check.
        const supported = await navigator.xr.isSessionSupported('immersive-ar');
        if (supported) {
          startButton.disabled = false;
          startButton.textContent = "Start AR";
          infoElement.innerText = "AR is supported! Click Start.";
          startButton.addEventListener('click', activateXR);
        } else {
          infoElement.innerText = "Immersive AR is not supported on this device/browser.";
        }
      } else {
        infoElement.innerText = "WebXR API not found. Use Chrome on an ARCore-supported Android device.";
      }
    });


    async function activateXR() {
      startButton.style.display = 'none';
      const canvas = document.createElement("canvas");
      document.body.appendChild(canvas);
      const gl = canvas.getContext("webgl", { xrCompatible: true });
      const scene = new THREE.Scene();

      // --- Boilerplate scene setup ---
      const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
      directionalLight.position.set(10, 15, 10);
      scene.add(directionalLight);
      const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
      scene.add(ambientLight);
      const renderer = new THREE.WebGLRenderer({ alpha: true, canvas: canvas, context: gl });
      renderer.autoClear = false;
      const camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;

      // --- Load resources first ---
      let trackedImageBitmap;
      const markerUrl = "https://cdn.jsdelivr.net/gh/hiukim/mind-ar-js@1.2.0/examples/image-tracking/assets/card-example/card.png";
      let flowerModel;
      try {
        infoElement.innerText = "Downloading resources...";
        const [imageResponse, gltf] = await Promise.all([
            fetch(markerUrl),
            new THREE.GLTFLoader().loadAsync("https://immersive-web.github.io/webxr-samples/media/gltf/sunflower/sunflower.gltf")
        ]);
        const blob = await imageResponse.blob();
        trackedImageBitmap = await createImageBitmap(blob);
        
        flowerModel = gltf.scene;
        flowerModel.scale.set(0.1, 0.1, 0.1);
        flowerModel.visible = false;
        scene.add(flowerModel);

      } catch (e) {
        infoElement.innerText = "Error: Failed to load resources.";
        console.error("Resource loading failed: ", e);
        startButton.style.display = 'block';
        return;
      }
      
      // --- Request a session and handle potential errors ---
      let session;
      try {
        session = await navigator.xr.requestSession("immersive-ar", {
          requiredFeatures: ['image-tracking'], // We ask for it here
          trackedImages: [{
            image: trackedImageBitmap,
            widthInMeters: 0.1
          }]
        });
      } catch (e) {
        // This CATCH block is the crucial part for handling the feature support error
        infoElement.innerHTML = `Failed to start AR session.<br><b>Image Tracking is likely not supported.</b><br>Please use latest Chrome on an ARCore-compatible Android device.`;
        console.error("Failed to request session:", e);
        startButton.style.display = 'block';
        return;
      }

      // --- If successful, proceed ---
      infoElement.innerText = "Point your camera at the marker image.";
      session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });
      const referenceSpace = await session.requestReferenceSpace('local');
      
      const onXRFrame = (time, frame) => {
        session.requestAnimationFrame(onXRFrame);
        const pose = frame.getViewerPose(referenceSpace);
        if (!pose) return;

        const results = frame.getTrackedImages();
        let imageFound = false;
        for (const result of results) {
          const imagePose = frame.getPose(result.imageSpace, referenceSpace);
          if (imagePose) {
            flowerModel.position.copy(imagePose.transform.position);
            flowerModel.quaternion.copy(imagePose.transform.orientation);
            flowerModel.visible = true;
            imageFound = true;
            infoElement.innerText = `Tracking state: ${result.trackingState}`;
          }
        }
        if (!imageFound) flowerModel.visible = false;

        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);
        const view = pose.views[0];
        const viewport = session.renderState.baseLayer.getViewport(view);
        renderer.setSize(viewport.width, viewport.height);
        camera.matrix.fromArray(view.transform.matrix);
        camera.projectionMatrix.fromArray(view.projectionMatrix);
        camera.updateMatrixWorld(true);
        renderer.render(scene, camera);
      };
      session.requestAnimationFrame(onXRFrame);
    }
  </script>
</body>
</html>